{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch packages\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "#training data\n",
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                              train = True,\n",
    "                              transform = transforms.ToTensor(),\n",
    "                              download = True)\n",
    "#testing dataset\n",
    "test_dataset = datasets.MNIST(root = './data',\n",
    "                            train = False,\n",
    "                            transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the dataset iterable \n",
    "#training load\n",
    "train_load = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True)\n",
    "#testing load\n",
    "test_load = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                       batch_size = batch_size,\n",
    "                                       shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 images in the training set\n",
      "There are 10000 images in the test set\n",
      "There are 600 images in the train loader\n",
      "There are 100 images in the test loader\n"
     ]
    }
   ],
   "source": [
    "#printing the size of the train and test data\n",
    "print('There are {} images in the training set'.format(len(train_dataset)))\n",
    "print('There are {} images in the test set'.format(len(test_dataset)))\n",
    "print('There are {} images in the train loader'.format(len(train_load)))\n",
    "print('There are {} images in the test loader'.format(len(test_load)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5,stride=1,padding=2)\n",
    "        #Batch Normalization\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        #RELU\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8,out_channels=32,kernel_size=5, stride=1,padding=2)\n",
    "        #2nd batch\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After pooling phase\n",
    "        self.fc1 = nn.Linear(in_features = 1568, out_features=600)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features = 10)\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #flatten the output\n",
    "        out = out.view(-1,1568)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CUDA for this project\n",
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "iter = 0 \n",
    "for epoch in range(epochs):\n",
    "    for i,(images,labels) in enumerate(train_load):\n",
    "        iter += 1\n",
    "        if CUDA:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #Test the model every 100 iterations. Calculate and print the testing accuracy\n",
    "            if(i +1) % 100 == 0:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images,labels in test_load:\n",
    "                    if CUDA:\n",
    "                        images = Variable(images.cuda())\n",
    "                    else:\n",
    "                        images = Variable(images)\n",
    "                        \n",
    "                    outputs = model(images)\n",
    "                    _,predicted = torch.max(outputs.data,1)\n",
    "                    total += labels.size(0)\n",
    "                    if CUDA:\n",
    "                        correct += (predicted.cpu()==labels.cpu()).sum()\n",
    "                    else:\n",
    "                        correct += (predicted==labels).sum()\n",
    "                        \n",
    "                accuracy = 100 * correct/total\n",
    "                print('iteration: {}, Train Loss: {}, Test Accuracy: {}%'.format(iter, loss.data[0], accuracy))\n",
    "print('DONE!')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
